{"cells":[{"cell_type":"markdown","metadata":{"id":"NXKzIFJOcXeU"},"source":["# Voice Conversion Training"]},{"cell_type":"markdown","metadata":{"id":"n9yhcim6cZ_F"},"source":["In this notebook we first load training data in the form of precomputed mel-spectrograms, content encodings and speaker encodings of the VCTK Dataset. Then we decide on a variant of our model to train, and lastly we run the training loop."]},{"cell_type":"markdown","metadata":{"id":"XufSxuq5Wn_k"},"source":["We make a few assumptions, for example about Google Drive folder structure. These will be apparent and you can adjust them if necessary."]},{"cell_type":"markdown","metadata":{"id":"hQwDz44iK1cV"},"source":["Parts of this notebook use Code from [Soft-VC](https://github.com/bshall/acoustic-model) as a basis."]},{"cell_type":"markdown","metadata":{"id":"0rDLONyJXEiw"},"source":["For loading the dataset and storing checkpoints, we mount Google Drive."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22587,"status":"ok","timestamp":1708451386027,"user":{"displayName":"Jannik Wei√ü","userId":"15600802440353476959"},"user_tz":-60},"id":"hg_mrM9JlxmO","outputId":"933cc789-7a6b-443f-c903-05b62c6fe54c"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Y5FU8W9vfG5J"},"source":["## Copy and unzip dataset from mounted Google Drive"]},{"cell_type":"markdown","metadata":{"id":"2chZqy1cXNjA"},"source":["We have found that copying the dataset files into a location inside the colab environment is much faster than working with the dataset if it stays in the mounted google drive folder. Adjust file paths if necessary."]},{"cell_type":"markdown","metadata":{"id":"e-Rd4GL3Xz4C"},"source":["Copying and unzipping the zip files usually takes around 1-2 minutes per cell for mel data and units."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"annjdXL_cdXc"},"outputs":[],"source":["drive_vctk_path = '/content/drive/MyDrive/VC/VCTK/'\n","drive_vctk_wav_text_path = drive_vctk_path + 'VCTK-Corpus-mic1.zip'\n","drive_vctk_mels_path = drive_vctk_path + 'VCTK-Corpus-mic1-mels.zip'\n","drive_vctk_units_path = drive_vctk_path + 'VCTK-Corpus-mic1-units.zip'\n","drive_vctk_spk_emb_path = drive_vctk_path + 'VCTK-Corpus-mic1-spk_emb.zip'\n","drive_vctk_spk_emb_win_path = drive_vctk_path + 'VCTK-Corpus-mic1-spk_emb_win.zip'\n","drive_vctk_spk_emb_agg_path = drive_vctk_path + 'VCTK-Corpus-mic1-spk_emb_agg.zip'\n","drive_vctk_splits_path = drive_vctk_path + 'splits_ext.json'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urrY-fXIcjpE"},"outputs":[],"source":["!mkdir /content/vctk"]},{"cell_type":"markdown","metadata":{"id":"qvxURHRLc98z"},"source":["copy mels from google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fSvMyJj2dAuq"},"outputs":[],"source":["!cp $drive_vctk_mels_path /content/vctk/VCTK-Corpus-mic1-mels.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sICcRZMndHxs"},"outputs":[],"source":["!unzip -q /content/vctk/VCTK-Corpus-mic1-mels.zip -d /content/vctk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BjEL41W2mHN1"},"outputs":[],"source":["!mv /content/vctk/content/vctk/mels /content/vctk/mels"]},{"cell_type":"markdown","metadata":{"id":"GGN317gUdWaW"},"source":["copy units from google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67XY6l2adWaY"},"outputs":[],"source":["!cp $drive_vctk_units_path /content/vctk/VCTK-Corpus-mic1-units.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_dxSBXjqdWaZ"},"outputs":[],"source":["!unzip -q /content/vctk/VCTK-Corpus-mic1-units.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uj7uCcMZnVNY"},"outputs":[],"source":["!mv /content/content/vctk/units /content/vctk/units"]},{"cell_type":"markdown","metadata":{"id":"iRGwVZuddeHo"},"source":["copy spk_emb from google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTmcoW2ddeHq"},"outputs":[],"source":["!cp $drive_vctk_spk_emb_path /content/vctk/VCTK-Corpus-mic1-spk_emb.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oX_n0mSDdeHq"},"outputs":[],"source":["!unzip -q /content/vctk/VCTK-Corpus-mic1-spk_emb.zip -d /content/vctk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MCPwPDi_nlh5"},"outputs":[],"source":["!mv /content/vctk/content/vctk/spk_emb /content/vctk/spk_emb"]},{"cell_type":"markdown","metadata":{"id":"9rFn7eNq7uzg"},"source":["copy spk_emb_win from google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2IMKMpih7tvJ"},"outputs":[],"source":["!cp $drive_vctk_spk_emb_win_path /content/vctk/VCTK-Corpus-mic1-spk_emb_win.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3X-hC9pV7tvN"},"outputs":[],"source":["!unzip -q /content/vctk/VCTK-Corpus-mic1-spk_emb_win.zip -d /content/vctk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0H7R4TDS7tvN"},"outputs":[],"source":["!mv /content/vctk/content/vctk/spk_emb_win /content/vctk/spk_emb_win"]},{"cell_type":"markdown","metadata":{"id":"a-e6lpG37y6O"},"source":["copy spk_emb_agg from google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WoYmGXKX7yTp"},"outputs":[],"source":["!cp $drive_vctk_spk_emb_agg_path /content/vctk/VCTK-Corpus-mic1-spk_emb_agg.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szx3baYb7yTq"},"outputs":[],"source":["!unzip -q /content/vctk/VCTK-Corpus-mic1-spk_emb_agg.zip -d /content/vctk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjFLLEaf7yTs"},"outputs":[],"source":["!mv /content/vctk/content/vctk/spk_emb_agg /content/vctk/spk_emb_agg"]},{"cell_type":"markdown","metadata":{"id":"BVCkgobrdrOr"},"source":["copy dataset split into from google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kALo87J4dxUz"},"outputs":[],"source":["!cp $drive_vctk_splits_path /content/vctk/splits.json"]},{"cell_type":"markdown","metadata":{"id":"yKV-cDUf7dXj"},"source":["create checkpoint directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBBU7x-x7fsh"},"outputs":[],"source":["!mkdir /content/ckpt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J8wLYk4lGwB8"},"outputs":[],"source":["vctk_path = \"/content/vctk\"\n","ckpt_path = \"/content/ckpt\"\n","splits_path = '/content/vctk/splits.json'\n","model_path = '/content/drive/MyDrive/VC'"]},{"cell_type":"markdown","metadata":{"id":"muMB5nRufW7G"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"MDop3HKjau8v"},"source":["This is the Dataset we use for training. `spkutts` is a list of speaker utterance id strings, e.g. `\"p225_001\"`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLXuMuqCfasp"},"outputs":[],"source":["from pathlib import Path\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","\n","class VCTKDataset(Dataset):\n","    def __init__(self, root, spkutts, spk_emb_type):\n","        if spk_emb_type == 'single':\n","            spk_emb_dirname = 'spk_emb'\n","        elif spk_emb_type == 'win':\n","            spk_emb_dirname = 'spk_emb_win'\n","        elif spk_emb_type == 'agg':\n","            spk_emb_dirname = 'spk_emb_agg'\n","        else:\n","            raise ValueError()\n","\n","        self.spk_emb_type = spk_emb_type\n","        self.mels_dir = root / \"mels\"\n","        self.units_dir = root / \"units\"\n","        self.spk_emb_dir = root / spk_emb_dirname\n","\n","        # EXAMPLE: self.metadata = [Path('p225/p225_001_mic1'), ...]\n","        self.metadata = [Path(f\"{spkutt[:4]}/{spkutt}_mic1\") for spkutt in spkutts]\n","\n","    def __len__(self):\n","        return len(self.metadata)\n","\n","    def __getitem__(self, index):\n","        path = self.metadata[index]\n","        mel_path = self.mels_dir / path\n","        units_path = self.units_dir / path\n","        if self.spk_emb_type in ['single', 'win']:\n","            spk_emb_path = self.spk_emb_dir / path\n","        else:  # self.spk_emb_type == 'agg'\n","            spk_emb_path = self.spk_emb_dir / Path(str(path)[:4])\n","\n","        mel = np.load(mel_path.with_suffix(\".npy\")).T\n","        units = np.load(units_path.with_suffix(\".npy\"))\n","        spk_emb = np.load(spk_emb_path.with_suffix(\".npy\"))\n","\n","        length = 2 * units.shape[0]\n","\n","        mel = torch.from_numpy(mel[:length, :])\n","        mel = F.pad(mel, (0, 0, 1, 0))\n","        units = torch.from_numpy(units)\n","        spk_emb = torch.from_numpy(spk_emb)\n","        return mel, units, spk_emb\n","\n","    def pad_collate(self, batch):\n","        mels, units, spk_embs = zip(*batch)\n","\n","        mels, units, spk_embs = list(mels), list(units), list(spk_embs)\n","\n","        mels_lengths = torch.tensor([x.size(0) - 1 for x in mels])\n","        units_lengths = torch.tensor([x.size(0) for x in units])\n","\n","        mels = pad_sequence(mels, batch_first=True)\n","        units = pad_sequence(\n","            units, batch_first=True, padding_value=0\n","        )\n","\n","        return mels, mels_lengths, units, units_lengths, spk_embs"]},{"cell_type":"markdown","metadata":{"id":"amYXJ9-iiKSn"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"kqJg5BSWbcIe"},"source":["Our model code lives in the file `model.py`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YJmP8UzupUYe"},"outputs":[],"source":["import sys\n","sys.path.append(model_path)\n","from model import VCModel"]},{"cell_type":"markdown","metadata":{"id":"_vzQACorjec-"},"source":["## Training Utils"]},{"cell_type":"markdown","metadata":{"id":"n0_oK4yFcGXQ"},"source":["Before we start the training loop, we need a few extra utils."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8oF2V6mjhH-"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import matplotlib\n","\n","import torchaudio.transforms as transforms\n","\n","\n","class Metric:\n","    def __init__(self):\n","        self.steps = 0\n","        self.value = 0\n","\n","    def update(self, value):\n","        self.steps += 1\n","        self.value += (value - self.value) / self.steps\n","        return self.value\n","\n","    def reset(self):\n","        self.steps = 0\n","        self.value = 0\n","\n","\n","\n","def save_checkpoint(\n","    checkpoint_dir,\n","    model,\n","    optimizer,\n","    step,\n","    loss,\n","    best,\n","    logger,\n","):\n","    state = {\n","        \"acoustic-model\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","        \"step\": step,\n","        \"loss\": loss,\n","    }\n","    checkpoint_dir.mkdir(exist_ok=True, parents=True)\n","    checkpoint_path = checkpoint_dir / f\"model-{step}.pt\"\n","    torch.save(state, checkpoint_path)\n","    if best:\n","        best_path = checkpoint_dir / \"model-best.pt\"\n","        torch.save(state, best_path)\n","    logger.info(f\"Saved checkpoint: {checkpoint_path.stem}\")\n"]},{"cell_type":"markdown","metadata":{"id":"38oH9O27jvBK"},"source":["## Training loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzAwCzGnFjP2"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"JbAexWqLIMPV"},"source":["Decide on the model variant and dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kqe1O3OUIAjO"},"outputs":[],"source":["MORE_DROPOUT = False\n","DIMINCREASE = False\n","POSTNET = False\n","\n","USE_CUSTOM_LSTM = False\n","\n","SPK_EMB_TYPE = 'agg'  # one of 'single', 'win', 'agg'\n","\n","VAL_ONLY_UNSEEN_SPK_AND_UTT = False"]},{"cell_type":"markdown","metadata":{"id":"dmv89HEbIHz1"},"source":["Initialize Model and Datasets and start the training loop"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"executionInfo":{"elapsed":9794,"status":"error","timestamp":1708452183290,"user":{"displayName":"Jannik Wei√ü","userId":"15600802440353476959"},"user_tz":-60},"id":"r4zExGWMjwuz","outputId":"4c3e59fb-0bc8-4a8b-892e-0b44dc37fa72"},"outputs":[],"source":["import logging\n","import json\n","from pathlib import Path\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","logging.basicConfig(level=logging.DEBUG)\n","logger = logging.getLogger(__name__)\n","\n","# Training Hyperparameters\n","\n","BATCH_SIZE = 64\n","LEARNING_RATE = 4e-4\n","BETAS = (0.8, 0.99)\n","WEIGHT_DECAY = 1e-5\n","STEPS = 45000  # around 80 Epochs\n","LOG_INTERVAL = 5\n","VALIDATION_INTERVAL = 547  # one 1 epoch is 547 steps\n","CHECKPOINT_INTERVAL = 547\n","\n","CHECKPOINT_DIR = Path(ckpt_path)\n","DATASET_DIR = Path(vctk_path)\n","\n","# Setup logging\n","\n","log_dir = CHECKPOINT_DIR / \"logs\"\n","log_dir.mkdir(exist_ok=True, parents=True)\n","\n","logger.setLevel(logging.INFO)\n","handler = logging.FileHandler(log_dir / f\"{CHECKPOINT_DIR.stem}.log\")\n","handler.setLevel(logging.INFO)\n","formatter = logging.Formatter(\n","    \"%(asctime)s [%(levelname)s] %(message)s\", datefmt=\"%m/%d/%Y %I:%M:%S\"\n",")\n","handler.setFormatter(formatter)\n","logger.addHandler(handler)\n","\n","writer = SummaryWriter(log_dir)\n","\n","# Initialize models and optimizer\n","\n","model = VCModel(\n","    more_dropout=MORE_DROPOUT,\n","    dimincrease=DIMINCREASE,\n","    postnet=POSTNET,\n","    use_custom_lstm=USE_CUSTOM_LSTM\n",").to('cuda')\n","\n","optimizer = optim.AdamW(\n","    model.parameters(),\n","    lr=LEARNING_RATE,\n","    betas=BETAS,\n","    weight_decay=WEIGHT_DECAY,\n",")\n","\n","# Initialize datasets and dataloaders\n","\n","with open(splits_path) as f:\n","    splits = json.load(f)\n","\n","train_dataset = VCTKDataset(\n","    root=DATASET_DIR,\n","    spkutts=splits[\"train\"],\n","    spk_emb_type=SPK_EMB_TYPE,\n",")\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    collate_fn=train_dataset.pad_collate,\n","    num_workers=1,\n","    pin_memory=True,\n","    shuffle=True,\n","    drop_last=True,\n",")\n","\n","if VAL_ONLY_UNSEEN_SPK_AND_UTT:\n","  validation_dataset_part = \"val_uu\"\n","else:\n","  validation_dataset_part = \"val\"\n","\n","validation_dataset = VCTKDataset(\n","    root=DATASET_DIR,\n","    spkutts=splits[validation_dataset_part],\n","    spk_emb_type=SPK_EMB_TYPE,\n",")\n","validation_loader = DataLoader(\n","    validation_dataset,\n","    batch_size=1,\n","    shuffle=False,\n","    num_workers=1,\n","    pin_memory=True,\n",")\n","\n","global_step, best_loss = 0, float(\"inf\")\n","\n","# Start training loop\n","\n","n_epochs = STEPS // len(train_loader) + 1\n","start_epoch = global_step // len(train_loader) + 1\n","\n","logger.info(\"**\" * 40)\n","logger.info(f\"PyTorch version: {torch.__version__}\")\n","logger.info(f\"CUDA version: {torch.version.cuda}\")\n","logger.info(f\"CUDNN version: {torch.backends.cudnn.version()}\")\n","logger.info(f\"CUDNN enabled: {torch.backends.cudnn.enabled}\")\n","logger.info(f\"CUDNN deterministic: {torch.backends.cudnn.deterministic}\")\n","logger.info(f\"CUDNN benchmark: {torch.backends.cudnn.benchmark}\")\n","logger.info(f\"# of GPUS: {torch.cuda.device_count()}\")\n","logger.info(f\"batch size: {BATCH_SIZE}\")\n","logger.info(f\"iterations per epoch: {len(train_loader)}\")\n","logger.info(f\"# of epochs: {n_epochs}\")\n","logger.info(f\"started at epoch: {start_epoch}\")\n","logger.info(\"**\" * 40 + \"\\n\")\n","\n","average_loss = Metric()\n","epoch_loss = Metric()\n","\n","validation_loss = Metric()\n","\n","for epoch in range(start_epoch, n_epochs + 1):\n","\n","    model.train()\n","    epoch_loss.reset()\n","\n","    for mels, mels_lengths, units, units_lengths, spk_embs in tqdm(train_loader):\n","        mels, mels_lengths = mels.to('cuda'), mels_lengths.to('cuda')\n","        units, units_lengths = units.to('cuda'), units_lengths.to('cuda')\n","        spk_embs = torch.stack(spk_embs)\n","        spk_embs = spk_embs.to('cuda')\n","\n","        # Compute training loss\n","\n","        optimizer.zero_grad()\n","\n","        mels_ = model(units, spk_embs, mels[:, :-1, :])\n","\n","        loss = F.l1_loss(mels_, mels[:, 1:, :], reduction=\"none\")\n","        loss = torch.sum(loss, dim=(1, 2)) / (mels_.size(-1) * mels_lengths)\n","        loss = torch.mean(loss)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        global_step += 1\n","\n","        # Update and log training metrics\n","\n","        average_loss.update(loss.item())\n","        epoch_loss.update(loss.item())\n","\n","        if global_step % LOG_INTERVAL == 0:\n","            writer.add_scalar(\n","                \"train/loss\",\n","                average_loss.value,\n","                global_step,\n","            )\n","            average_loss.reset()\n","\n","        # Start validation loop\n","\n","        if global_step % VALIDATION_INTERVAL == 0:\n","            model.eval()\n","            validation_loss.reset()\n","\n","            for i, (mels, units, spk_embs) in enumerate(validation_loader, 1):\n","                mels, units = mels.to('cuda'), units.to('cuda')\n","                spk_embs = spk_embs.to('cuda')\n","\n","                with torch.no_grad():\n","                    mels_ = model(units, spk_embs, mels[:, :-1, :])\n","                    loss = F.l1_loss(mels_, mels[:, 1:, :])\n","\n","                # Update validation metrics\n","\n","                validation_loss.update(loss.item())\n","\n","            model.train()\n","\n","            # Log validation metrics\n","\n","            writer.add_scalar(\n","                \"validation/loss\",\n","                validation_loss.value,\n","                global_step,\n","            )\n","            logger.info(\n","                f\"valid -- epoch: {epoch}, loss: {validation_loss.value:.4f}\"\n","            )\n","\n","            new_best = best_loss > validation_loss.value\n","            if new_best or global_step % CHECKPOINT_INTERVAL == 0:\n","                if new_best:\n","                    logger.info(\"-------- new best model found!\")\n","                    best_loss = validation_loss.value\n","\n","                save_checkpoint(\n","                    checkpoint_dir=CHECKPOINT_DIR,\n","                    model=model,\n","                    optimizer=optimizer,\n","                    step=global_step,\n","                    loss=validation_loss.value,\n","                    best=new_best,\n","                    logger=logger,\n","                )\n","\n","        # End validation loop\n","\n","    # Log training metrics\n","\n","    logger.info(f\"train -- epoch: {epoch}, loss: {epoch_loss.value:.4f}\")\n","\n","    # End training loop"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
